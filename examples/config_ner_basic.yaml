# =============================================================================
# Example 1: Basic NER Training (English, span mode)
# =============================================================================
# A minimal configuration for training a GLiNER span-based NER model
# on English text using DeBERTa-v3-small as the backbone.
#
# Usage:
#   python -m ptbr config --file examples/config_ner_basic.yaml --validate
#   python -m ptbr train main examples/config_ner_basic.yaml
# =============================================================================

run:
  name: "gliner-ner-basic"
  description: "Basic English NER fine-tuning with DeBERTa-v3-small"
  tags:
    - "ner"
    - "english"
    - "span"
  seed: 42

model:
  model_name: "microsoft/deberta-v3-small"
  name: "gliner-ner-basic"
  span_mode: "markerV0"
  max_width: 12
  hidden_size: 768
  dropout: 0.3
  fine_tune: true
  subtoken_pooling: "first"
  max_len: 384
  max_types: 25
  max_neg_type_ratio: 1

data:
  root_dir: "logs/ner_basic"
  train_data: "data/train.json"
  val_data_dir: "none"

training:
  num_steps: 10000
  train_batch_size: 8
  eval_every: 500
  warmup_ratio: 0.1
  scheduler_type: "cosine"
  lr_encoder: 1.0e-5
  lr_others: 3.0e-5
  weight_decay_encoder: 0.01
  weight_decay_other: 0.01
  max_grad_norm: 10.0
  optimizer: "adamw_torch"
  loss_alpha: -1
  loss_gamma: 0
  label_smoothing: 0
  loss_reduction: "sum"
  bf16: false
  save_total_limit: 3
  dataloader_num_workers: 2

lora:
  enabled: false

environment:
  push_to_hub: false
  report_to: "none"
